This is a draft....


Process   

When the first Random Faces came in there was that moment of excitement that something new, raw and unexpected provokes. Two years of experimentation had yielded 'it'. An initial intention had been thoroughly subverted by the reality of the medium - code.   

Our starting vision had been to collect and sort head shots of people by similarity of facial structure - instead of individuality, a continuum. As photos came in, they could find their place in the line-up. The goal was to provoke that same mode of perception that visually scanning facial morphologies in public places presents.   

The first curve thrown by code was dimensionality. Conceptually, the line exploded into the 60 'axes' we admitted through the code. Instead of using a line-up, the continuum was now visually fitted to a coordinate system. Understanding what happened there (and imagining educational settings through which this knowledge could be shared) occupied some time.   

Another hurdle was how to acquire faces. Research databases are available, but not for re-publication. To set up a controlled situation to take photos was deemed too time intensive. Instead, the Antiface App was created to entice people to submit photos. A lot of coding went into constraining the images to achieve sufficient control over lighting, position and frame.   

In the end, we were more thrilled by the Antifaces than the faces we received. So we took a break and did a few other things.   

Project   

Relegated to the background of attention, the Random Faces erupted out of sheer playfulness. Our medium had pointed us to our project. The goal to provoke a mode of perception is still intact, but delivered differently. The vision has become more complex and exciting. Serendipitously, that happened just a few days before the DevArt contest was published.   

With the initial frame broken down, how to output the faces is now our big question. Surface, scale and level of interactivity are to be determined. Are there multiple environments? Interfaces?   

To think through ideas and constraints, we used a scheme one of us has developed, the [Fractal 3-Line Matrix](http://usefulpictures.com/2013/04/11/so-what-is-this-3-line-matrix/). This evening we stopped by the installation at the Sullivan Galleries on State Street which has 3-Line Matrix white boards to assist with just this kind of inquiry.   

![p1](../project_images/adelheidNotes.jpg?raw=true)

The diagram that result is show immediately below. It indicates three high level concerns: Input (what we have and know how to do), Output (how we may show results), Ecologies (what are the contexts).   
![p1](../project_images/croppedSmall.jpg?raw=true)

Zooming in on the smaller matrices, one-by-one:
Left Top: This concerns the Dev end of the Dev/Art Axis. Our development concerns span both real faces from the audience and reconstructed faces from the model. The problem of dimensionality is how to represent 60 dimensional space in three dimensions. Our architecture is also indicated.
![p1](../project_images/ul.JPG?raw=true)

The center axis on the main matrix deals with how we present the art, as light or as paper. The 'light' sub-matrix options are broken out by Screen, Projection, Interface.
![p1](../project_images/ml.JPG?raw=true)

Left Bottom: User Ecologies: Audiences, Sponsors, Arts Organizations
![p1](../project_images/ll.JPG?raw=true)

Right top: Maker Ecologies: I.T., Academia, Markets
![p1](../project_images/ur.JPG?raw=true)

Right center: Output to Paper options: Quality, Presentation, Economy
![p1](../project_images/mr.JPG?raw=true)

Right Bottom: Input from Art: Observe, Frame, Materialize
![p1](../project_images/lr.JPG?raw=true)






